# Thursday, February 3rd, 2022


## <a id="ko">Kunle Olukoton - _The Future of AI Systems - Let the Data Flow!_</a>

<a id="ko_ab"></a>**Abstract:** As the benefits from Moore’s Law diminish, future computing performance improvements must
rely on specialized accelerators for applications in high performance computing, artificial
intelligence, and traditional data processing. These challenging applications are characterized
by terabyte sized models, data sparsity and irregular control flow. In this talk, we explain how
Reconfigurable Dataflow Accelerators (RDAs) can be used to accelerate a broad set of dataintensive
applications with these characteristics. SambaNova Systems is using RDA technology
contained in Reconfigurable Dataflow Units (RDUs) to achieve record‐setting performance on
challenging machine learning tasks. We will describe how RDAs can also be used to accelerate
database and HPC applications with irregular control and data flow using a new execution
model called Dataflow threads.


<a id="ko_bio"></a>**Biography:** Kunle Olukotun is the Cadence Design Professor of Electrical Engineering and
Computer Science at Stanford University. Olukotun is a pioneer in multi-core processor
design and the leader of the Stanford Hydra chip multiprocessor (CMP) research
project.

In 2017 Olukotun co-founded SambaNova Systems, a Machine Learning and Artificial
Intelligence company, and continues to lead as their Chief Technologist. Prior to
SambaNova Systems, Olukotun founded Afara Websystems to develop highthroughput,
low-power multi-core processors for server systems. The Afara multi-core
processor, called Niagara, was acquired by Sun Microsystems and now powers
Oracle’s SPARC-based servers.

Olukotun is the Director of the Pervasive Parallel Lab and a member of the Data Analytics for What’s Next (DAWN) Lab, developing infrastructure for usable machine learning. Olukotun is also an ACM Fellow and IEEE Fellow for contributions to multiprocessors on a chip and multi-threaded processor design. He recently won the IEEE Computer Society’s Harry H. Goode Memorial Award and was also elected to the National Academy of Engineering. Kunle received his Ph.D. in Computer Engineering from The University of Michigan.

## <a id="rg"> Roberto Gioiosa - _Re‐Imagining HW/SW Co‐Design: a Flexible, Composable, and Agile approach_</a>

<a id="rg_ab"></a>**Abstract:** The need of processing and analyzing extremely large amount of data with real‐time and power/energy constraints has motivated the development of many highly‐specialized and energy  efficient  architectural  concepts.  This  trend  is  evident  in  embedded  systems,  such  as  mobile  phones  or  smart  sensors,  where  systems  contain  a  myriad  of  small,  specialized  ASIC processors. Large‐scale, HPC systems have also embraced heterogeneous devices to speed up computation while maintaining a strict power budget. Looking forward, one can imagine that more application‐specific accelerators will be incorporated into SoC designs, which will contain general‐purpose,  programmable  processing  elements,  such  as  CPU  and  GPU  cores,  fixed,  application‐specific  accelerators  (e.g.,  FFT  or  GEMM),  and  semi‐programmable  CGRA  devices. Designing such increasingly complex device become and incredibly difficult task.  

In the AI space, this revolution is already happening, with many custom hardware designs already available. The Center for co‐design of ARtificial Intelligence focused Architectures and Algorithms (ARIAA)  is  a  DOE/ASCR  project  lead  by  Pacific  Northwest  National  Laboratory  (PNNL)  in  collaboration with Sandia National Laboratory (SNL), Georgia Tech (GT), NVIDIA, and Qualcomm. ARIAA’s  objectives  are  to  co‐design  novel  architectures,  algorithms,  and  programming  abstractions to enable AI‐based DOE applications and support sparse, explainable, and domain‐informed AI models. Ultimately, ARIAA aims at understanding how AI‐focused architectures can accelerate traditional, emerging, and AI DOE workloads, identifying computational kernels that can  be  effectively  replaced  by  accurate  AI/ML  methods,  identifying  opportunities  to  leverage  AI/ML methods to support computation and data analytics, and understanding and designing AI accelerators for future explainable and domain‐aware AI methods. This talk will describe ARIAA’s novel approach to co‐design of AI/HPC accelerators, programming abstractions, and algorithms and how various technologies are integrated to form and end‐to‐end solution. 

<a id="rg_bio"></a>**Bio:** Dr. Roberto Gioiosa is a senior research scientist at the Pacific Northwest National Laboratory (PNNL) in the High‐Performance Computing Group and team lead of the Scalable and Emerging Technology  Team  (SET).  His  research  interests  include  operating  systems  and  runtimes,  high‐performance  computer  architectures,  memory,  and  networks,  parallel  and  distributed programming models, resilience, performance and power modeling and analysis, and embedded systems.  

Dr. Gioiosa earned his Ph.D. in 2006 from the University of Rome "Tor Vergara", Rome Italy. He has  worked  at  the  Los  Alamos  National  Laboratory  (LANL)  (2004‐2005),  the  Barcelona  Supercomputing Center (BSC) (2006‐2008 and 2009‐2012), the IBM T.J. Watson Research Center (2008‐2009) where he contributed to the development of the Compute Node Kernel for BG/Q systems, and Oak Ridge National Laboratory (ORNL) (2017‐2018).

Currently, his projects include the development of system software for extremely heterogeneous systems, system software for scalable distributed systems, DSSoC design, evaluation of emerging architecture  and  technologies  for  exascale  systems  and  applications,  and  development  of  operating systems for exascale systems. Dr. Gioiosa leads the DOE/ASCR Center for co‐design of ARtificial Intelligence focused Architectures and Algorithms (ARIAA). He is a member of the ACM and IEEE Computer Society.  
